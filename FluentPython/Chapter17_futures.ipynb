{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN FLAGS_PY\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import requests  # <1>\n",
    "\n",
    "POP20_CC = ('CN IN US ID BR PK NG BD RU JP '\n",
    "            'MX PH VN ET EG DE IR TR CD FR').split()  # <2>\n",
    "\n",
    "BASE_URL = 'http://flupy.org/data/flags'  # <3>\n",
    "\n",
    "DEST_DIR = 'downloads/'  # <4>\n",
    "\n",
    "\n",
    "def save_flag(img, filename):  # <5>\n",
    "    path = os.path.join(DEST_DIR, filename)\n",
    "    with open(path, 'wb') as fp:\n",
    "        fp.write(img)\n",
    "\n",
    "\n",
    "def get_flag(cc):  # <6>\n",
    "    url = '{}/{cc}/{cc}.gif'.format(BASE_URL, cc=cc.lower())\n",
    "    resp = requests.get(url)\n",
    "    return resp.content\n",
    "\n",
    "\n",
    "def show(text):  # <7>\n",
    "    print(text, end=' ')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "def download_many(cc_list):  # <8>\n",
    "    for cc in sorted(cc_list):  # <9>\n",
    "        image = get_flag(cc)\n",
    "        show(cc)\n",
    "        save_flag(image, cc.lower() + '.gif')\n",
    "\n",
    "    return len(cc_list)\n",
    "\n",
    "\n",
    "def main(download_many):  # <10>\n",
    "    t0 = time.time()\n",
    "    count = download_many(POP20_CC)\n",
    "    elapsed = time.time() - t0\n",
    "    msg = '\\n{} flags downloaded in {:.2f}s'\n",
    "    print(msg.format(count, elapsed))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(download_many)  # <11>\n",
    "# END FLAGS_PY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    使用单线程下载\n",
    "    \n",
    "'''\n",
    "\n",
    "import os\n",
    "import requests\n",
    "\n",
    "POP20_CC = ('CN IN US ID BR PK NG BD RU JP '\n",
    "            'MX PH VN ET EG DE IR TR CD FR').split()  # <2>\n",
    "\n",
    "BASE_URL = 'http://flupy.org/data/flags'  # <3>\n",
    "\n",
    "DEST_DIR = 'downloads/'  # <4>\n",
    "\n",
    "def save_flag(img, filename):\n",
    "    path = os.path.join(DEST_DIR, filename)\n",
    "    with open(path, 'wb') as fp:\n",
    "        fp.write(img)\n",
    "    \n",
    "\n",
    "def get_flag(cc):\n",
    "    url = '{}/{cc}/{cc}.gif'.format(BASE_URL, cc = cc.lower())\n",
    "    resp = requests.get(url)\n",
    "    return resp.content\n",
    "\n",
    "\n",
    "\n",
    "def download_flags(cc_list):\n",
    "    for cc in cc_list:\n",
    "        img = get_flag(cc)\n",
    "        save_flag(img, cc.lower() + '.gif')\n",
    "    return len(cc_list)\n",
    "\n",
    "def main():\n",
    "    import time\n",
    "    t0 = time.time()\n",
    "    download_flags(POP20_CC)\n",
    "    t1 = time.time() - t0\n",
    "    print('downloud time is {:.2f}s'.format(t1))\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    使用多线程\n",
    "'''\n",
    "\n",
    "import os\n",
    "import requests\n",
    "\n",
    "from concurrent import futures\n",
    "\n",
    "POP20_CC = ('CN IN US ID BR PK NG BD RU JP '\n",
    "            'MX PH VN ET EG DE IR TR CD FR').split()  # <2>\n",
    "\n",
    "BASE_URL = 'http://flupy.org/data/flags'  # <3>\n",
    "\n",
    "DEST_DIR = 'downloads/'  # <4>\n",
    "\n",
    "def save_flag(img, filename):\n",
    "    path = os.path.join(DEST_DIR, filename)\n",
    "    with open(path, 'wb') as fp:\n",
    "        fp.write(img)\n",
    "    \n",
    "\n",
    "def get_flag(cc):\n",
    "    url = '{}/{cc}/{cc}.gif'.format(BASE_URL, cc = cc.lower())\n",
    "    resp = requests.get(url)\n",
    "    return resp.content\n",
    "\n",
    "\n",
    "def download_flags(cc_list):\n",
    "    for cc in cc_list:\n",
    "        img = get_flag(cc)\n",
    "        save_flag(img, cc.lower() + '.gif')\n",
    "    return len(cc_list)\n",
    "\n",
    "\n",
    "def download_one(cc):\n",
    "    img = get_flag(cc)\n",
    "    save_flag(img, cc.lower() + '.gif')\n",
    "\n",
    "\n",
    "def download_many_conc(cc_list):\n",
    "    MAX_WORKERS = 20\n",
    "    workers = min(MAX_WORKERS, len(cc_list))\n",
    "    with futures.ThreadPoolExecutor(workers) as executor:\n",
    "        res = executor.map(download_one, sorted(cc_list))\n",
    "    return len(list(res))\n",
    "\n",
    "\n",
    "def main(download_flags_func):\n",
    "    import time\n",
    "    t0 = time.time()\n",
    "    download_flags_func(POP20_CC)\n",
    "    t1 = time.time() - t0\n",
    "    print('downloud time is {:.2f}s'.format(t1))\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main(download_many_conc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "为了从实用的角度理解future，我们可以使用concurrent.futures.as_completed函数重写示例17-3。\n",
    "这个函数的参数是一个future列表，返回值是一个迭代器，在future运行结束后产出future。\n",
    "'''\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "from concurrent import futures\n",
    "\n",
    "POP20_CC = ('CN IN US ID BR PK NG BD RU JP '\n",
    "            'MX PH VN ET EG DE IR TR CD FR').split()  # <2>\n",
    "\n",
    "BASE_URL = 'http://flupy.org/data/flags'  # <3>\n",
    "\n",
    "DEST_DIR = 'downloads/'  # <4>\n",
    "\n",
    "def save_flag(img, filename):\n",
    "    path = os.path.join(DEST_DIR, filename)\n",
    "    with open(path, 'wb') as fp:\n",
    "        fp.write(img)\n",
    "    \n",
    "\n",
    "def get_flag(cc):\n",
    "    url = '{}/{cc}/{cc}.gif'.format(BASE_URL, cc = cc.lower())\n",
    "    resp = requests.get(url)\n",
    "    return resp.content\n",
    "\n",
    "\n",
    "def download_flags(cc_list):\n",
    "    for cc in cc_list:\n",
    "        img = get_flag(cc)\n",
    "        save_flag(img, cc.lower() + '.gif')\n",
    "    return len(cc_list)\n",
    "\n",
    "\n",
    "def download_one(cc):\n",
    "    img = get_flag(cc)\n",
    "    save_flag(img, cc.lower() + '.gif')\n",
    "    return cc\n",
    "\n",
    "\n",
    "def download_many_conc(cc_list):\n",
    "    MAX_WORKERS = 20\n",
    "    workers = min(MAX_WORKERS, len(cc_list))\n",
    "    with futures.ThreadPoolExecutor(workers) as executor:\n",
    "        res = executor.map(download_one, sorted(cc_list))\n",
    "    return len(list(res))\n",
    "\n",
    "\n",
    "def download_many_conc2(cc_list):\n",
    "    cc_list = cc_list[:5]\n",
    "    with futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        to_do = []\n",
    "        for cc in sorted(cc_list):\n",
    "            future = executor.submit(download_one, cc)\n",
    "            to_do.append(future)\n",
    "            msg = 'Scheduled for {}: {}'\n",
    "            print(msg.format(cc, future))\n",
    "        results = []\n",
    "        # time.sleep(10.0)\n",
    "        for future in futures.as_completed(to_do):\n",
    "            res = future.result()\n",
    "            msg = '{} result: {!r}'\n",
    "            print( msg.format(future, res))\n",
    "            results.append(res)\n",
    "    return len(results)\n",
    "\n",
    "\n",
    "def main(download_flags_func):\n",
    "\n",
    "    t0 = time.time()\n",
    "    download_flags_func(POP20_CC)\n",
    "    t1 = time.time() - t0\n",
    "    print('downloud time is {:.2f}s'.format(t1))\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main(download_many_conc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent import futures\n",
    "\n",
    "MAX_WORKERS = 20\n",
    "\n",
    "def downloud_one(cc):\n",
    "    image = get_flag(cc)\n",
    "    show(cc)\n",
    "    save_flag(image, cc.lower() + \".gif\")\n",
    "    return cc\n",
    "\n",
    "# ++++++++++++++++++++++++++++++++++++++++\n",
    "def download_many_cc(cc_list):\n",
    "    workers = min(MAX_WORKERS, len(cc_list))\n",
    "    with futures.ThreadPoolExecutor(workers) as executor :\n",
    "        res = executor.map(downloud_one, sorted(cc_list))\n",
    "    \n",
    "    return len(list(res))\n",
    "# ----------------------------------------\n",
    "\n",
    "def main(download_many):  # <10>\n",
    "    t0 = time.time()\n",
    "    count = download_many(POP20_CC)\n",
    "    elapsed = time.time() - t0\n",
    "    msg = '\\n{} flags downloaded in {:.2f}s'\n",
    "    print(msg.format(count, elapsed))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(download_many_cc)  # <11>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "做个简单的比喻：进程（process）=火车，线程（thread）=车厢\n",
    "\n",
    "- 线程在进程下行进（单纯的车厢无法运行）\n",
    "- 一个进程可以包含多个线程（一辆火车可以有多个车厢）\n",
    "- 不同进程间数据很难共享（一辆火车上的乘客很难换到另外一辆火车，比如站点换乘）\n",
    "- 同一进程下不同线程间数据很易共享（A车厢换到B车厢很容易）\n",
    "- 进程要比线程消耗更多的计算机资源（采用多列火车相比多个车厢更耗资源）\n",
    "- 进程间不会相互影响，一个线程挂掉将导致整个进程挂掉（一列火车不会影响到另外一列火车，但是如果一列火车上中间的一节车厢着火了，将影响到所有车厢）\n",
    "- 进程可以拓展到多机，进程最多适合多核（不同火车可以开在多个轨道上，同一火车的车厢不能在行进的不同的轨道上）\n",
    "- 进程使用的内存地址可以上锁，即一个线程使用某些共享内存时，其他线程必须等它结束，才能使用这一块内存。（比如火车上的洗手间）－\"互斥锁\"\n",
    "- 进程使用的内存地址可以限定使用量（比如火车上的餐厅，最多只允许多少人进入，如果满了需要在门口等，等有人出来了才能进去）－“信号量”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for循环中的enumerate函数会隐式调用next(results)，这个函数又会在（内部）表示第一个任务（loiter(0)）的_f future上调用_f.result（　）方法。result方法会阻塞，直到future运行结束，因此这个循环每次迭代时都要等待下一个结果做好准备。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "严格来说，我们目前测试的并发脚本都不能并行下载。使用concurrent.futures库实现的那两个示例受GIL（GlobalInterpreter Lock，全局解释器锁）的限制，而fags_asyncio.py脚本在单个线程中运行。读到这里，你可能会对前面做的非正规基准测试有下述疑问。\n",
    "\n",
    "- 既然Python线程受GIL的限制，任何时候都只允许运行一个线程，那么fags_threadpool.py脚本的下载速度怎么会比fags.py脚本快5倍？\n",
    "- fags_asyncio.py脚本和fags.py脚本都在单个线程中运行，前者怎么会比后者快5倍？\n",
    "\n",
    "第一个问题：\n",
    "\n",
    "CPython解释器本身就不是线程安全的，因此有全局解释器锁（GIL），一次只允许使用一个线程执行Python字节码。因此，一个Python进程通常不能同时使用多个CPU核心。然而，标准库中所有执行阻塞型I/O操作的函数，在等待操作系统返回结果时都会释放GIL。这意味着在Python语言这个层次上可以使用多线程，而I/O密集型Python程序能从中受益：一个Python线程等待网络响应时，阻塞型I/O函数会释放GIL，再运行一个线程。\n",
    "\n",
    "这个模块实现的是真正的并行计算，因为它使用ProcessPoolExecutor类把工作分配给多个Python进程处理。\n",
    "\n",
    "ProcessPoolExecutor和ThreadPoolExecutor类都实现了通用的Executor接口，因此使用concurrent.futures模块能特别轻松地把基于线程的方案转成基于进程的方案。\n",
    "\n",
    "ThreadPoolExecutor.__init__方法需要max_workers参数，指定线程池中线程的数量。在ProcessPoolExecutor类中，那个参数是可选的，而且大多数情况下不使用——默认值是os.cpu_count（　）函数返回的CPU数量。这样处理说得通，因为对CPU密集型的处理来说，不可能要求使用超过CPU数量的职程。而对I/O密集型处理来说，可以在一个ThreadPoolExecutor实例中使用10个、100个或1000个线程；最佳线程数取决于做的是什么事，以及可用内存有多少，因此要仔细测试才能找到最佳的线程数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProcessPoolExecutor vs ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 0.46s\n",
      "elapsed time: 0.90s\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "\"\"\"RC4 compatible algorithm\"\"\"\n",
    "\n",
    "def arcfour(key, in_bytes, loops=20):\n",
    "\n",
    "    kbox = bytearray(256)  # create key box\n",
    "    for i, car in enumerate(key):  # copy key and vector\n",
    "        kbox[i] = car\n",
    "    j = len(key)\n",
    "    for i in range(j, 256):  # repeat until full\n",
    "        kbox[i] = kbox[i-j]\n",
    "\n",
    "    # [1] initialize sbox\n",
    "    sbox = bytearray(range(256))\n",
    "    # repeat sbox mixing loop, as recommened in CipherSaber-2\n",
    "    # http://ciphersaber.gurus.com/faq.html#cs2\n",
    "    j = 0\n",
    "    for k in range(loops):\n",
    "        for i in range(256):\n",
    "            j = (j + sbox[i] + kbox[i]) % 256\n",
    "            sbox[i], sbox[j] = sbox[j], sbox[i]\n",
    "    # main loop\n",
    "    i = 0\n",
    "    j = 0\n",
    "    out_bytes = bytearray()\n",
    "\n",
    "    for car in in_bytes:\n",
    "        i = (i + 1) % 256\n",
    "        # [2] shuffle sbox\n",
    "        j = (j + sbox[i]) % 256\n",
    "        sbox[i], sbox[j] = sbox[j], sbox[i]\n",
    "        # [3] compute t\n",
    "        t = (sbox[i] + sbox[j]) % 256\n",
    "        k = sbox[t]\n",
    "        car = car ^ k\n",
    "        out_bytes.append(car)\n",
    "\n",
    "    return out_bytes\n",
    "\n",
    "\n",
    "def test():\n",
    "    from time import time\n",
    "    clear = bytearray(b'1234567890' * 100000)\n",
    "    t0 = time()\n",
    "    cipher = arcfour(b'lzk', clear)\n",
    "    print('elapsed time: %.2fs' % (time() - t0))\n",
    "    result = arcfour(b'lzk', cipher)\n",
    "    assert result == clear, '%r != %r' % (result, clear)\n",
    "    print('elapsed time: %.2fs' % (time() - t0))\n",
    "    print('OK')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "107\n",
      "1\n",
      "101\n",
      "2\n",
      "121\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "key = b'key'\n",
    "kbox = bytearray(256)  # create key box\n",
    "for i, car in enumerate(key):  # copy key and vector\n",
    "    print(i)\n",
    "    print(car)\n",
    "    kbox[i] = car\n",
    "\n",
    "print(key[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'randrange' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/process.py\", line 239, in _process_worker\n    r = call_item.fn(*call_item.args, **call_item.kwargs)\n  File \"/Users/liuzhongkai/Documents/Git/PythonScript/FluentPython/arcfour.py\", line 53, in arcfour_test\n    in_text = bytearray(randrange(256) for i in range(size))\n  File \"/Users/liuzhongkai/Documents/Git/PythonScript/FluentPython/arcfour.py\", line 53, in <genexpr>\n    in_text = bytearray(randrange(256) for i in range(size))\nNameError: name 'randrange' is not defined\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-bbe0cec7d453>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mworkers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-bbe0cec7d453>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(workers)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_completed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_do\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{:.1f} KB'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'randrange' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    arcfour futures\n",
    "'''\n",
    "import sys\n",
    "import time\n",
    "from concurrent import futures\n",
    "from random import randrange\n",
    "from arcfour import *\n",
    "\n",
    "JOBS = 12\n",
    "SIZE = 2**18\n",
    "\n",
    "KEY = b\"'Twas brillig, and the slithy toves\\nDid gyre\"\n",
    "STATUS = '{} workers, elapsed time: {:.2f}s'\n",
    "\n",
    "\n",
    "\n",
    "def main(workers=None):\n",
    "    if workers:\n",
    "        workers = int(workers)\n",
    "    t0 = time.time()\n",
    "\n",
    "    with futures.ProcessPoolExecutor(workers) as executor:\n",
    "        actual_workers = executor._max_workers\n",
    "        to_do = []\n",
    "        for i in range(JOBS, 0, -1):\n",
    "            size = SIZE + int(SIZE / JOBS * (i - JOBS/2))\n",
    "            job = executor.submit(arcfour_test, size, KEY)\n",
    "            to_do.append(job)\n",
    "\n",
    "        for future in futures.as_completed(to_do):\n",
    "            res = future.result()\n",
    "            print('{:.1f} KB'.format(res/2**10))\n",
    "\n",
    "    print(STATUS.format(actual_workers, time.time() - t0))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if len(sys.argv) == 2:\n",
    "        workers = int(sys.argv[1])\n",
    "    else:\n",
    "        workers = None\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-aeb3f719a5e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mworkers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-aeb3f719a5e8>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(workers)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mto_do\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSIZE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJOBS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_completed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_do\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBrokenProcessPool\u001b[0m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "'''\n",
    "    sha\n",
    "'''\n",
    "import sys\n",
    "import time\n",
    "import hashlib\n",
    "from concurrent import futures\n",
    "from random import randrange\n",
    "\n",
    "JOBS = 12\n",
    "SIZE = 2**20\n",
    "STATUS = '{} workers, elapsed time: {:.2f}s'\n",
    "\n",
    "\n",
    "def sha(size):\n",
    "    data = bytearray(randrange(256) for i in range(size))\n",
    "    algo = hashlib.new('sha256')\n",
    "    algo.update(data)\n",
    "    return algo.hexdigest()\n",
    "\n",
    "\n",
    "def main(workers=None):\n",
    "    if workers:\n",
    "        workers = int(workers)\n",
    "    t0 = time.time()\n",
    "\n",
    "    with futures.ProcessPoolExecutor(workers) as executor:\n",
    "        actual_workers = executor._max_workers\n",
    "        to_do = (executor.submit(sha, SIZE) for i in range(JOBS))\n",
    "        for future in futures.as_completed(to_do):\n",
    "            res = future.result()\n",
    "            print(res)\n",
    "\n",
    "    print(STATUS.format(actual_workers, time.time() - t0))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if len(sys.argv) == 2:\n",
    "        workers = int(sys.argv[1])\n",
    "    else:\n",
    "        workers = None\n",
    "    main(workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.\n",
    "\n",
    "关于这个问题，从网上查了下，找到的解决方案似乎不起作用：\n",
    "\n",
    "[Multiprocessing in Python on Windows and Jupyter/Ipython — Making it work](https://medium.com/@grvsinghal/speed-up-your-python-code-using-multiprocessing-on-windows-and-jupyter-or-ipython-2714b49d6fac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  实验Executor.map方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:56:44] Script Starting.\n",
      "[13:56:44] loiter(0) : doing nothing for 0s\n",
      "[13:56:44] \tloiter(1) : doing nothing for 1s\n",
      "[13:56:44] loiter(0) : done\n",
      "[13:56:44] \t\tloiter(2) : doing nothing for 2s\n",
      "[13:56:44] results: <generator object Executor.map.<locals>.result_iterator at 0x7fa6b8c6b7b0>\n",
      "[13:56:44] Waiting for individual results:\n",
      "[13:56:44] result 0 : 0\n",
      "[13:56:44] \t\t\tloiter(3) : doing nothing for 3s\n",
      "[13:56:45] \tloiter(1) : done\n",
      "[13:56:45] \t\t\t\tloiter(4) : doing nothing for 4s\n",
      "[13:56:45] result 1 : 10\n",
      "[13:56:46] \t\tloiter(2) : done\n",
      "[13:56:46] result 2 : 20\n",
      "[13:56:47] \t\t\tloiter(3) : done\n",
      "[13:56:47] result 3 : 30\n",
      "[13:56:49] \t\t\t\tloiter(4) : done\n",
      "[13:56:49] result 4 : 40\n"
     ]
    }
   ],
   "source": [
    "from time import sleep, strftime\n",
    "from concurrent import futures\n",
    "\n",
    "def display(*args):\n",
    "    print(strftime('[%H:%M:%S]'), end = ' ')\n",
    "    print(*args)\n",
    "\n",
    "def loiter(n):\n",
    "    msg = '{}loiter({}) : doing nothing for {}s'\n",
    "    display(msg.format('\\t'*n, n, n))\n",
    "    sleep(n)\n",
    "    msg = '{}loiter({}) : done'\n",
    "    display(msg.format('\\t'*n, n))\n",
    "    return n * 10\n",
    "\n",
    "def main():\n",
    "    display('Script Starting.')\n",
    "    executor = futures.ThreadPoolExecutor(max_workers=3)\n",
    "    # 这一行表明，executor.map方法返回的结果（results）是生成器；不管有多少任务，也不管max_workers的值是多少，目前不会阻塞。\n",
    "    results = executor.map(loiter, range(5)) \n",
    "    display('results:', results)\n",
    "    display('Waiting for individual results:')\n",
    "    for i, result in enumerate(results):\n",
    "        display('result {} : {}'.format(i, result))\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executor.map函数易于使用，不过有个特性可能有用，也可能没用，具体情况取决于需求：这个函数返回结果的顺序与调用开始的顺序一致。如果第一个调用生成结果用时10秒，而其他调用只用1秒，代码会阻塞10秒，获取map方法返回的生成器产出的第一个结果。在此之后，获取后续结果时不会阻塞，因为后续的调用已经结束。如果必须等到获取所有结果后再处理，这种行为没问题；不过，通常更可取的方式是，不管提交的顺序，只要有结果就获取。\n",
    "\n",
    "executor.submit和futures.as_completed这个组合比executor.map更灵活，因为submit方法能处理不同的可调用对象和参数，而executor.map只能处理参数不同的同一个可调用对象。\n",
    "\n",
    "executor.submit和futures.as_completed这个组合比executor.map更灵活，因为submit方法能处理不同的可调用对象和参数，而executor.map只能处理参数不同的同一个可调用对象。此外，传给futures.as_completed函数的future集合可以来自多个Executor实例，例如一些由ThreadPoolExecutor实例创建，另一些由ProcessPoolExecutor实例创建。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17.5 显示下载进度并处理错误"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Utilities for second set of flag examples.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import string\n",
    "import argparse\n",
    "from collections import namedtuple\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "Result = namedtuple('Result', 'status data')\n",
    "\n",
    "HTTPStatus = Enum('Status', 'ok not_found error')\n",
    "\n",
    "POP20_CC = ('AA CN IN US ID BR PK NG BD RU JP NN'\n",
    "            'MX PH VN ET EG DE IR TR CD FR').split()\n",
    "\n",
    "DEFAULT_CONCUR_REQ = 1\n",
    "MAX_CONCUR_REQ = 1\n",
    "\n",
    "SERVERS = {\n",
    "    'REMOTE': 'http://flupy.org/data/flags',\n",
    "    'LOCAL':  'http://localhost:8001/flags',\n",
    "    'DELAY':  'http://localhost:8002/flags',\n",
    "    'ERROR':  'http://localhost:8003/flags',\n",
    "}\n",
    "DEFAULT_SERVER = 'LOCAL'\n",
    "\n",
    "DEST_DIR = 'downloads/'\n",
    "COUNTRY_CODES_FILE = 'country_codes.txt'\n",
    "\n",
    "\n",
    "def save_flag(img, filename):\n",
    "    path = os.path.join(DEST_DIR, filename)\n",
    "    with open(path, 'wb') as fp:\n",
    "        fp.write(img)\n",
    "\n",
    "\n",
    "def initial_report(cc_list, actual_req, server_label):\n",
    "    if len(cc_list) <= 10:\n",
    "        cc_msg = ', '.join(cc_list)\n",
    "    else:\n",
    "        cc_msg = 'from {} to {}'.format(cc_list[0], cc_list[-1])\n",
    "    print('{} site: {}'.format(server_label, SERVERS[server_label]))\n",
    "    msg = 'Searching for {} flag{}: {}'\n",
    "    plural = 's' if len(cc_list) != 1 else ''\n",
    "    print(msg.format(len(cc_list), plural, cc_msg))\n",
    "    plural = 's' if actual_req != 1 else ''\n",
    "    msg = '{} concurrent connection{} will be used.'\n",
    "    print(msg.format(actual_req, plural))\n",
    "\n",
    "\n",
    "def final_report(cc_list, counter, start_time):\n",
    "    elapsed = time.time() - start_time\n",
    "    print('-' * 20)\n",
    "    msg = '{} flag{} downloaded.'\n",
    "    plural = 's' if counter[HTTPStatus.ok] != 1 else ''\n",
    "    print(msg.format(counter[HTTPStatus.ok], plural))\n",
    "    if counter[HTTPStatus.not_found]:\n",
    "        print(counter[HTTPStatus.not_found], 'not found.')\n",
    "    if counter[HTTPStatus.error]:\n",
    "        plural = 's' if counter[HTTPStatus.error] != 1 else ''\n",
    "        print('{} error{}.'.format(counter[HTTPStatus.error], plural))\n",
    "    print('Elapsed time: {:.2f}s'.format(elapsed))\n",
    "\n",
    "\n",
    "def expand_cc_args(every_cc, all_cc, cc_args, limit):\n",
    "    codes = set()\n",
    "    A_Z = string.ascii_uppercase\n",
    "    if every_cc:\n",
    "        codes.update(a+b for a in A_Z for b in A_Z)\n",
    "    elif all_cc:\n",
    "        with open(COUNTRY_CODES_FILE) as fp:\n",
    "            text = fp.read()\n",
    "        codes.update(text.split())\n",
    "    else:\n",
    "        for cc in (c.upper() for c in cc_args):\n",
    "            if len(cc) == 1 and cc in A_Z:\n",
    "                codes.update(cc+c for c in A_Z)\n",
    "            elif len(cc) == 2 and all(c in A_Z for c in cc):\n",
    "                codes.add(cc)\n",
    "            else:\n",
    "                msg = 'each CC argument must be A to Z or AA to ZZ.'\n",
    "                raise ValueError('*** Usage error: '+msg)\n",
    "    return sorted(codes)[:limit]\n",
    "\n",
    "\n",
    "def process_args(default_concur_req):\n",
    "    server_options = ', '.join(sorted(SERVERS))\n",
    "    parser = argparse.ArgumentParser(\n",
    "                description='Download flags for country codes. '\n",
    "                'Default: top 20 countries by population.')\n",
    "    parser.add_argument('cc', metavar='CC', nargs='*',\n",
    "                help='country code or 1st letter (eg. B for BA...BZ)')\n",
    "    parser.add_argument('-a', '--all', action='store_true',\n",
    "                help='get all available flags (AD to ZW)')\n",
    "    parser.add_argument('-e', '--every', action='store_true',\n",
    "                help='get flags for every possible code (AA...ZZ)')\n",
    "    parser.add_argument('-l', '--limit', metavar='N', type=int,\n",
    "                help='limit to N first codes', default=sys.maxsize)\n",
    "    parser.add_argument('-m', '--max_req', metavar='CONCURRENT', type=int,\n",
    "                default=default_concur_req,\n",
    "                help='maximum concurrent requests (default={})'\n",
    "                      .format(default_concur_req))\n",
    "    parser.add_argument('-s', '--server', metavar='LABEL',\n",
    "                default=DEFAULT_SERVER,\n",
    "                help='Server to hit; one of {} (default={})'\n",
    "                      .format(server_options, DEFAULT_SERVER))\n",
    "    parser.add_argument('-v', '--verbose', action='store_true',\n",
    "                help='output detailed progress info')\n",
    "    args = parser.parse_args()\n",
    "    if args.max_req < 1:\n",
    "        print('*** Usage error: --max_req CONCURRENT must be >= 1')\n",
    "        parser.print_usage()\n",
    "        sys.exit(1)\n",
    "    if args.limit < 1:\n",
    "        print('*** Usage error: --limit N must be >= 1')\n",
    "        parser.print_usage()\n",
    "        sys.exit(1)\n",
    "    args.server = args.server.upper()\n",
    "    if args.server not in SERVERS:\n",
    "        print('*** Usage error: --server LABEL must be one of',\n",
    "              server_options)\n",
    "        parser.print_usage()\n",
    "        sys.exit(1)\n",
    "    try:\n",
    "        cc_list = expand_cc_args(args.every, args.all, args.cc, args.limit)\n",
    "    except ValueError as exc:\n",
    "        print(exc.args[0])\n",
    "        parser.print_usage()\n",
    "        sys.exit(1)\n",
    "\n",
    "    if not cc_list:\n",
    "        cc_list = sorted(POP20_CC)\n",
    "    return args, cc_list\n",
    "\n",
    "\n",
    "def main(download_many, default_concur_req, max_concur_req):\n",
    "    # args = \n",
    "    cc_list = sorted(POP20_CC)\n",
    "    actual_req = min(5, max_concur_req, len(cc_list))\n",
    "    initial_report(cc_list, actual_req, 'REMOTE')\n",
    "    base_url = SERVERS['REMOTE']\n",
    "    t0 = time.time()\n",
    "    counter = download_many(cc_list, base_url, False, actual_req)\n",
    "    assert sum(counter.values()) == len(cc_list), \\\n",
    "        'some downloads are unaccounted for'\n",
    "    final_report(cc_list, counter, t0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现依序下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOTE site: http://flupy.org/data/flags\n",
      "Searching for 21 flags: from AA to VN\n",
      "1 concurrent connection will be used.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tqdm.std.tqdm'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:24<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "19 flags downloaded.\n",
      "2 not found.\n",
      "Elapsed time: 24.07s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Download flags of countries (with error handling).\n",
    "\n",
    "Sequential version\n",
    "\n",
    "Sample run::\n",
    "\n",
    "    $ python3 flags2_sequential.py -s DELAY b\n",
    "    DELAY site: http://localhost:8002/flags\n",
    "    Searching for 26 flags: from BA to BZ\n",
    "    1 concurrent connection will be used.\n",
    "    --------------------\n",
    "    17 flags downloaded.\n",
    "    9 not found.\n",
    "    Elapsed time: 13.36s\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import collections\n",
    "\n",
    "import requests\n",
    "import tqdm\n",
    "\n",
    "\n",
    "\n",
    "DEFAULT_CONCUR_REQ = 1\n",
    "MAX_CONCUR_REQ = 1\n",
    "\n",
    "# BEGIN FLAGS2_BASIC_HTTP_FUNCTIONS\n",
    "def get_flag(base_url, cc):\n",
    "    url = '{}/{cc}/{cc}.gif'.format(base_url, cc=cc.lower())\n",
    "    resp = requests.get(url)\n",
    "    if resp.status_code != 200:  # get_flag函数没有处理错误，当HTTP代码不是200(success)时，使用requests.Response.raise_for_status方法抛出异常。\n",
    "        resp.raise_for_status()\n",
    "    return resp.content\n",
    "\n",
    "\n",
    "def download_one(cc, base_url, verbose=False):\n",
    "    try:\n",
    "        image = get_flag(base_url, cc)\n",
    "    except requests.exceptions.HTTPError as exc:  # download_one函数捕获requests.exceptions.HTTPError异常，特别处理HTTP 404错误……\n",
    "        res = exc.response\n",
    "        if res.status_code == 404:\n",
    "            status = HTTPStatus.not_found  #  ……方法是，把局部变量status设为HTTPStatus.not_found；HTTPStatus是从fags2_common模块（见示例A-10）中导入的Enum对象\n",
    "            msg = 'not found'\n",
    "        else:  # 重新抛出其他HTTPError异常；这些异常会向上冒泡，传给调用方\n",
    "            raise\n",
    "    else:\n",
    "        save_flag(image, cc.lower() + '.gif')\n",
    "        status = HTTPStatus.ok\n",
    "        msg = 'OK'\n",
    "\n",
    "    if verbose:  # 如果在命令行中设定了-v/--verbose选项，显示国家代码和状态消息；这就是详细模式中看到的进度信息。\n",
    "        print(cc, msg)\n",
    "\n",
    "    return Result(status, cc)  # download_one函数的返回值是一个namedtuple——Result，其中有个status字段，其值是HTTPStatus.not_found或HTTPStatus.ok。\n",
    "# END FLAGS2_BASIC_HTTP_FUNCTIONS\n",
    "\n",
    "# BEGIN FLAGS2_DOWNLOAD_MANY_SEQUENTIAL 实现依序下载的download_many函数\n",
    "def download_many(cc_list, base_url, verbose, max_req):\n",
    "    counter = collections.Counter()  # 这个Counter实例用于统计不同的下载状态：HTTPStatus.ok、HTTPStatus.not_found或HTTPStatus.error。\n",
    "    cc_iter = sorted(cc_list)  # 按字母顺序传入的国家代码列表，保存在cc_iter变量中。\n",
    "    if not verbose:\n",
    "        cc_iter = tqdm.tqdm(cc_iter)  # 如果不是详细模式，把cc_iter传给tqdm函数，返回一个迭代器，产出cc_iter中的元素，还会显示进度条动画。\n",
    "\n",
    "    for cc in cc_iter:  # 这个for循环迭代cc_iter……\n",
    "        try:\n",
    "            res = download_one(cc, base_url, verbose)  # ……不断调用download_one函数，执行下载。\n",
    "        except requests.exceptions.HTTPError as exc:  # 处理get_fag函数抛出的与HTTP有关的且download_one函数没有处理的异常。\n",
    "            error_msg = 'HTTP error {res.status_code} - {res.reason}'\n",
    "            error_msg = error_msg.format(res=exc.response)\n",
    "        except requests.exceptions.ConnectionError as exc:  # 处理其他与网络有关的异常。其他异常会中止这个脚本，因为调用download_many函数的fags2_common.main函数中没有try/except块。\n",
    "            error_msg = 'Connection error'\n",
    "        else:  # 如果没有异常从download_one函数中逃出，从download_one函数返回的namedtuple（HTTPStatus）中获取status。\n",
    "            error_msg = ''\n",
    "            status = res.status\n",
    "\n",
    "        if error_msg:\n",
    "            status = HTTPStatus.error  #  如果有错误，把局部变量status设为相应的状态。\n",
    "        counter[status] += 1  #  如果有错误，把局部变量status设为相应的状态。\n",
    "        if verbose and error_msg: # 如果是详细模式，而且有错误，显示带有当前国家代码的错误消息。\n",
    "            print('*** Error for {}: {}'.format(cc, error_msg))\n",
    "\n",
    "    return counter  # 返回counter，以便main函数能在最终的报告中显示数量。\n",
    "# END FLAGS2_DOWNLOAD_MANY_SEQUENTIAL\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(download_many, DEFAULT_CONCUR_REQ, MAX_CONCUR_REQ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  使用futures.as_completed函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOTE site: http://flupy.org/data/flags\n",
      "Searching for 21 flags: from AA to VN\n",
      "5 concurrent connections will be used.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:07<00:00,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "19 flags downloaded.\n",
      "2 not found.\n",
      "Elapsed time: 7.62s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Download flags of countries (with error handling).\n",
    "\n",
    "ThreadPool version\n",
    "\n",
    "Sample run::\n",
    "\n",
    "    $ python3 flags2_threadpool.py -s ERROR -e\n",
    "    ERROR site: http://localhost:8003/flags\n",
    "    Searching for 676 flags: from AA to ZZ\n",
    "    30 concurrent connections will be used.\n",
    "    --------------------\n",
    "    150 flags downloaded.\n",
    "    361 not found.\n",
    "    165 errors.\n",
    "    Elapsed time: 7.46s\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# BEGIN FLAGS2_THREADPOOL\n",
    "import collections\n",
    "from concurrent import futures\n",
    "\n",
    "import requests\n",
    "import tqdm  # <1>\n",
    "\n",
    "# from flags2_common import main, HTTPStatus  # <2>\n",
    "# from flags2_sequential import download_one  # <3>\n",
    "\n",
    "DEFAULT_CONCUR_REQ = 30  # 如果没有在命令行中指定-m/--max_req选项，使用这个值作为并发请求数的最大值，也就是线程池的大小；真实的数量可能会比这少，例如下载的国旗数量较少。\n",
    "MAX_CONCUR_REQ = 1000  # <5>\n",
    "\n",
    "\n",
    "def download_many(cc_list, base_url, verbose, concur_req):\n",
    "    counter = collections.Counter()\n",
    "    with futures.ThreadPoolExecutor(max_workers=concur_req) as executor:  # 把max_workers设为concur_req，创建ThreadPoolExecutor实例； main函数会把下面这三个值中最小的那个赋值给concur_req：MAX_CONCUR_REQ、cc_list的长度、-m/--max_req命令行选项的值。这样能避免创建超过所需的线程。\n",
    "        to_do_map = {}  # 这个字典把各个Future实例（表示一次下载）映射到相应的国家代码上，在处理错误时使用。\n",
    "        for cc in sorted(cc_list):  # 按字母顺序迭代国家代码列表。结果的顺序主要由HTTP响应的时间长短决定，不过，如果线程池的大小（由concur_req设定）比len(cc_list)小得多，可能会发现有按字母顺序批量下载的情况。\n",
    "            future = executor.submit(download_one,\n",
    "                            cc, base_url, verbose)  # 每次调用executor.submit方法排定一个可调用对象的执行时间，然后返回一个Future实例。第一个参数是可调用的对象，其余的参数是传给可调用对象的参数。\n",
    "            to_do_map[future] = cc  # 把返回的future和国家代码存储在字典中。\n",
    "        done_iter = futures.as_completed(to_do_map)  #  futures.as_completed函数返回一个迭代器，在future运行结束后产出future。\n",
    "        if not verbose:\n",
    "            done_iter = tqdm.tqdm(done_iter, total=len(cc_list))  # 如果不是详细模式，把as_completed函数返回的结果传给tqdm函数，显示进度条；因为done_iter没有len函数，所以我们必须通过total=参数告诉tqdm函数预期的元素数量，这样tqdm才能预计剩余的工作量。\n",
    "        for future in done_iter:  # 迭代运行结束后的future。\n",
    "            try:\n",
    "                res = future.result()  # 在future上调用result方法，要么返回可调用对象的返回值，要么抛出可调用的对象在执行过程中捕获的异常。这个方法可能会阻塞，等待确定结果；不过，在这个示例中不会阻塞，因为as_completed函数只返回已经运行结束的future。\n",
    "            except requests.exceptions.HTTPError as exc:  # 处理可能出现的异常；这个函数余下的代码与依序下载版download_many函数一样（见示例17-13），不过下一点除外。\n",
    "                error_msg = 'HTTP {res.status_code} - {res.reason}'\n",
    "                error_msg = error_msg.format(res=exc.response)\n",
    "            except requests.exceptions.ConnectionError as exc:\n",
    "                error_msg = 'Connection error'\n",
    "            else:\n",
    "                error_msg = ''\n",
    "                status = res.status\n",
    "\n",
    "            if error_msg:\n",
    "                status = HTTPStatus.error\n",
    "            counter[status] += 1\n",
    "            if verbose and error_msg:\n",
    "                cc = to_do_map[future]  # 为了给错误消息提供上下文，以当前的future为键，从to_do_map中获取国家代码。在依序下载版中无须这么做，因为那一版迭代的是国家代码，所以知道当前国家的代码；而这里迭代的是future。\n",
    "                print('*** Error for {}: {}'.format(cc, error_msg))\n",
    "\n",
    "    return counter\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(download_many, DEFAULT_CONCUR_REQ, MAX_CONCUR_REQ)\n",
    "# END FLAGS2_THREADPOOL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线程和多进程的替代方案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Download flags of countries (with error handling).\n",
    "\n",
    "asyncio async/await version\n",
    "\n",
    "\"\"\"\n",
    "# BEGIN FLAGS2_ASYNCIO_TOP\n",
    "import asyncio\n",
    "import collections\n",
    "\n",
    "import aiohttp\n",
    "from aiohttp import web\n",
    "import tqdm\n",
    "\n",
    "\n",
    "\n",
    "# default set low to avoid errors from remote site, such as\n",
    "# 503 - Service Temporarily Unavailable\n",
    "DEFAULT_CONCUR_REQ = 5\n",
    "MAX_CONCUR_REQ = 1000\n",
    "\n",
    "\n",
    "class FetchError(Exception):  # <1>\n",
    "    def __init__(self, country_code):\n",
    "        self.country_code = country_code\n",
    "\n",
    "\n",
    "async def get_flag(session, base_url, cc): # <2>\n",
    "    url = '{}/{cc}/{cc}.gif'.format(base_url, cc=cc.lower())\n",
    "    async with session.get(url) as resp:\n",
    "        if resp.status == 200:\n",
    "            return await resp.read()\n",
    "        elif resp.status == 404:\n",
    "            raise web.HTTPNotFound()\n",
    "        else:\n",
    "            raise aiohttp.HttpProcessingError(\n",
    "                code=resp.status, message=resp.reason,\n",
    "                headers=resp.headers)\n",
    "\n",
    "\n",
    "async def download_one(session, cc, base_url, semaphore, verbose):  # <3>\n",
    "    try:\n",
    "        async with semaphore:  # <4>\n",
    "            image = await get_flag(session, base_url, cc)  # <5>\n",
    "    except web.HTTPNotFound:  # <6>\n",
    "        status = HTTPStatus.not_found\n",
    "        msg = 'not found'\n",
    "    except Exception as exc:\n",
    "        raise FetchError(cc) from exc  # <7>\n",
    "    else:\n",
    "        save_flag(image, cc.lower() + '.gif')  # <8>\n",
    "        status = HTTPStatus.ok\n",
    "        msg = 'OK'\n",
    "\n",
    "    if verbose and msg:\n",
    "        print(cc, msg)\n",
    "\n",
    "    return Result(status, cc)\n",
    "# END FLAGS2_ASYNCIO_TOP\n",
    "\n",
    "# BEGIN FLAGS2_ASYNCIO_DOWNLOAD_MANY\n",
    "async def downloader_coro(cc_list, base_url, verbose, concur_req):  # <1>\n",
    "    counter = collections.Counter()\n",
    "    semaphore = asyncio.Semaphore(concur_req)  # <2>\n",
    "    async with aiohttp.ClientSession() as session:  # <8>\n",
    "        to_do = [download_one(session, cc, base_url, semaphore, verbose)\n",
    "                for cc in sorted(cc_list)]  # <3>\n",
    "\n",
    "        to_do_iter = asyncio.as_completed(to_do)  # <4>\n",
    "        if not verbose:\n",
    "            to_do_iter = tqdm.tqdm(to_do_iter, total=len(cc_list))  # <5>\n",
    "        for future in to_do_iter:  # <6>\n",
    "            try:\n",
    "                res = await future  # <7>\n",
    "            except FetchError as exc:  # <8>\n",
    "                country_code = exc.country_code  # <9>\n",
    "                try:\n",
    "                    error_msg = exc.__cause__.args[0]  # <10>\n",
    "                except IndexError:\n",
    "                    error_msg = exc.__cause__.__class__.__name__  # <11>\n",
    "                if verbose and error_msg:\n",
    "                    msg = '*** Error for {}: {}'\n",
    "                    print(msg.format(country_code, error_msg))\n",
    "                status = HTTPStatus.error\n",
    "            else:\n",
    "                status = res.status\n",
    "\n",
    "            counter[status] += 1  # <12>\n",
    "\n",
    "    return counter  # <13>\n",
    "\n",
    "\n",
    "def download_many(cc_list, base_url, verbose, concur_req):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    coro = downloader_coro(cc_list, base_url, verbose, concur_req)\n",
    "    counts = loop.run_until_complete(coro)  # <14>\n",
    "    loop.close()  # <15>\n",
    "\n",
    "    return counts\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(download_many, DEFAULT_CONCUR_REQ, MAX_CONCUR_REQ)\n",
    "# END FLAGS2_ASYNCIO_DOWNLOAD_MANY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对CPU密集型工作来说，要启动多个进程，规避GIL。创建多个进程最简单的方式是，使用futures.ProcessPoolExecutor类。不过和前面一样，如果使用场景较复杂，需要更高级的工具。multiprocessing模块的API与threading模块相仿，不过作业交给多个进程处理。对简单的程序来说，可以用multiprocessing模块代替threading模块，少量改动即可。不过，multiprocessing模块还能解决协作进程遇到的最大挑战：在进程之间传递数据。"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e6db7d16afb9d2b05a6270becd2d66f0676bfd807f06b7702e9e3df3fb7a71ca"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
